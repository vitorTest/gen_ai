{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modeling is a process of automatically identifying the topics present in a text corpus, it derives the hidden patterns among the words in the corpus in an unsupervised manner. Topics are defined as “a repeating pattern of co-occurring terms in a corpus”. Topic modelling can be described as a method for finding a group of words (i.e topic) from a collection of documents that best represents the information in the collection.\n",
    "\n",
    "As the name suggests, it is a process to automatically identify topics present in a text object and to derive hidden patterns exhibited by a text corpus. Thus, assisting better decision making. \n",
    "\n",
    "Topic Modelling is different from rule-based text mining approaches that use regular expressions or dictionary based keyword searching techniques. It is an unsupervised approach used for finding and observing the bunch of words (called “topics”) in large clusters of texts.\n",
    "\n",
    "A good topic model results in – “health”, “doctor”, “patient”, “hospital” for a topic – Healthcare, and “farm”, “crops”, “wheat” for a topic – “Farming”.\n",
    "\n",
    "Topic Models are very useful for the purpose for document clustering, organizing large blocks of textual data, information retrieval from unstructured text and feature selection. For Example – New York Times are using topic models to boost their user – article recommendation engines. Various professionals are using topic models for recruitment industries where they aim to extract latent features of job descriptions and map them to right candidates. They are being used to organize large datasets of emails, customer reviews, and user social media profiles.\n",
    "\n",
    "There are many approaches for obtaining topics from a text such as – Term Frequency and Inverse Document Frequency (TfIdf). NonNegative Matrix Factorization techniques. Latent Dirichlet Allocation(LDA) is the most popular topic modeling technique and in this article, we will discuss the same.\n",
    "\n",
    "LDA assumes documents are produced from a mixture of topics. Those topics then generate words based on their probability distribution. Given a dataset of documents, LDA backtracks and tries to figure out what topics would create those documents in the first place.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see how it works with the following sentences.\n",
    "\n",
    "doc1 = \"I have big exam tomorrow and I need to study hard to get a good grade.\"\n",
    "doc2 = \"My wife likes to go out with me but I prefer staying at home and studying.\"\n",
    "doc3 = \"Kids are playing football in the field and they seem to have fun\"\n",
    "doc4 = \"Sometimes I feel depressed while driving and it's hard to focus on the road.\"\n",
    "doc5 = \"I usually prefer reading at home but my wife prefers watching a TV.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array of documents aka corpus\n",
    "corpus = [doc1, doc2, doc3, doc4, doc5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['big', 'exam', 'tomorrow', 'need', 'study', 'hard', 'get', 'good', 'grade'],\n",
       " ['wife', 'likes', 'go', 'prefer', 'staying', 'home', 'studying'],\n",
       " ['kids', 'playing', 'football', 'field', 'seem', 'fun'],\n",
       " ['sometimes', 'feel', 'depressed', 'driving', 'hard', 'focus', 'road'],\n",
       " ['usually', 'prefer', 'reading', 'home', 'wife', 'prefers', 'watching', 'tv']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets prepare our corpus to be used in LDA. We'll usee the same functions we wrote before\n",
    "# First, we are creating a dictionary from the data, then convert to bag-of-words corpus.\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "token_list=[]\n",
    "for sentence in corpus:\n",
    "    token_list.append(tokenizer.tokenize(sentence.lower()))\n",
    "\n",
    "\n",
    "def remove_stopwords(words):\n",
    "\n",
    "    filtered_words = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_words.append(word)\n",
    "            \n",
    "    return filtered_words\n",
    "\n",
    "    \n",
    "tokenized_data=[]\n",
    "\n",
    "for token in token_list:\n",
    "    #distinct_tokens=list(set(token))\n",
    "    tokenized_data.append(remove_stopwords(token))\n",
    "    # we at first remove punctuations and then stopwords\n",
    "\n",
    "\n",
    "tokenized_data\n",
    "# now here are the tokens for each sentence inside the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LDA model discovers the different topics that the documents represent and how much of each topic is present in a document. \n",
    "\n",
    "Python provides many great libraries for text mining practices, “gensim” is one such clean and beautiful library to handle text data. It is scalable, robust and efficient. Following code shows how to convert a corpus into a document-term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: 0.030*\"prefer\" + 0.030*\"wife\" + 0.030*\"hard\" + 0.030*\"reading\" + 0.030*\"playing\"\n",
      "Topic #1: 0.118*\"seem\" + 0.118*\"kids\" + 0.118*\"fun\" + 0.118*\"football\" + 0.118*\"field\"\n",
      "Topic #2: 0.030*\"prefer\" + 0.030*\"wife\" + 0.030*\"hard\" + 0.030*\"depressed\" + 0.030*\"reading\"\n",
      "Topic #3: 0.030*\"prefer\" + 0.030*\"wife\" + 0.030*\"home\" + 0.030*\"go\" + 0.030*\"fun\"\n",
      "Topic #4: 0.109*\"hard\" + 0.057*\"good\" + 0.057*\"exam\" + 0.057*\"study\" + 0.057*\"get\"\n",
      "Topic #5: 0.107*\"home\" + 0.107*\"staying\" + 0.107*\"studying\" + 0.107*\"likes\" + 0.107*\"wife\"\n",
      "Topic #6: 0.030*\"prefer\" + 0.030*\"hard\" + 0.030*\"wife\" + 0.030*\"focus\" + 0.030*\"home\"\n",
      "Topic #7: 0.030*\"wife\" + 0.030*\"prefer\" + 0.030*\"playing\" + 0.030*\"football\" + 0.030*\"sometimes\"\n",
      "Topic #8: 0.097*\"watching\" + 0.097*\"prefer\" + 0.097*\"home\" + 0.097*\"tv\" + 0.097*\"prefers\"\n",
      "Topic #9: 0.030*\"wife\" + 0.030*\"prefer\" + 0.030*\"playing\" + 0.030*\"hard\" + 0.030*\"home\"\n"
     ]
    }
   ],
   "source": [
    "# first import corpora and models module from gensim package\n",
    "from gensim import corpora, models\n",
    "\n",
    "# Build a Dictionary - association word to numeric id\n",
    "dictionary = corpora.Dictionary(tokenized_data)\n",
    " \n",
    "# Transform the collection of texts to a numerical form\n",
    "numerical_corpus = [dictionary.doc2bow(text) for text in tokenized_data]\n",
    "\n",
    "# Build the LDA model\n",
    "# We are asking LDA to find 10 topics in the data\n",
    "lda_model = models.LdaModel(corpus=numerical_corpus, num_topics=10, id2word=dictionary)\n",
    "\n",
    "for idx in range(10):\n",
    "    # Print the first 10 most representative topics\n",
    "    print(\"Topic #%s:\" % idx, lda_model.print_topic(idx, 5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we trained and built our LDA model over the five simple sentences, whenever we want to detect the topic of a new sentence or text, we'll at first prepare the text and then push that into our model to get a topic. Let's try to predict a topic for a new sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.033333335),\n",
       " (1, 0.033333335),\n",
       " (2, 0.033333335),\n",
       " (3, 0.033333335),\n",
       " (4, 0.033333335),\n",
       " (5, 0.6999944),\n",
       " (6, 0.033333335),\n",
       " (7, 0.033333335),\n",
       " (8, 0.033338886),\n",
       " (9, 0.033333335)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sentence=\"My wife plans to go out tonight\"\n",
    "lda_model.get_document_topics(dictionary.doc2bow(new_sentence.split()) )\n",
    "# dictionary.doc2bow command only accepts bag of word list.. \n",
    "# so, without applying any cleaning, we just use splitting to create a list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.033333335),\n",
       " (1, 0.033333335),\n",
       " (2, 0.033333335),\n",
       " (3, 0.033333335),\n",
       " (4, 0.033333335),\n",
       " (5, 0.6999944),\n",
       " (6, 0.033333335),\n",
       " (7, 0.033333335),\n",
       " (8, 0.033338886),\n",
       " (9, 0.033333335)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also use bag of words as an index in LDA model and would get the same output\n",
    "lda_model[dictionary.doc2bow(new_sentence.split())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as you can see, topic-5 (listed above) is the most relevant topic (0.699) for this sentence.\n",
    "\n",
    "Topic #5: 0.107*\"home\" + 0.107*\"staying\" + 0.107*\"studying\" + 0.107*\"likes\" + 0.107*\"wife\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I have big exam tomorrow and I need to study hard to get a good grade.', 'My wife likes to go out with me but I prefer staying at home and studying.', 'Kids are playing football in the field and they seem to have fun']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33695588 0.355996   0.36244625 0.35599533 0.35112408]\n"
     ]
    }
   ],
   "source": [
    "# We can also use LDA model to find the similarities between documents.\n",
    "# Gensim offers a simple way of performing similarity queries using topic models.\n",
    "\n",
    "new_sentence=\"We are going play soccer with the kids\"\n",
    "\n",
    "from gensim import similarities\n",
    " \n",
    "lda_index = similarities.MatrixSimilarity(lda_model[numerical_corpus])\n",
    "\n",
    "# bag of word of the target sentence\n",
    "bow=dictionary.doc2bow(new_sentence.split())\n",
    "\n",
    "# Let's perform some queries\n",
    "similarities = lda_index[lda_model[bow]]\n",
    " \n",
    "# document similarity scores:\n",
    "\n",
    "print(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as you see, the highest score is 0.36244625 and it belongs to doc_3\n",
    "# doc3 = \"Kids are playing football in the field and they seem to have fun\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
